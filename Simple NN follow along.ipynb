{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "#Generate data to train on\n",
    "observations = 1000\n",
    "\n",
    "xs = np.random.uniform(low=-10,high=10,size=(observations,1))\n",
    "zs = np.random.uniform(-10,10,(observations,1))\n",
    "\n",
    "inputs = np.column_stack((xs,zs))\n",
    "\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Create the targets we will aim at\n",
    "noise = np.random.uniform(-1,1,(observations,1))\n",
    "\n",
    "targets = 2*xs - 3*zs + 5 + noise\n",
    "\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise variables\n",
    "init_range = 0.1\n",
    "\n",
    "weights = np.random.uniform(-init_range,init_range,size = (2,1))\n",
    "\n",
    "biases = np.random.uniform(-init_range,init_range,size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set a learning rate\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211.46276847976213\n",
      "103.54631822599949\n",
      "53.958676559221814\n",
      "31.104312456517277\n",
      "20.50444526395024\n",
      "15.52366702727403\n",
      "13.120858486850858\n",
      "11.902116414129043\n",
      "11.22848154404881\n",
      "10.807017397642953\n",
      "10.503393708607\n",
      "10.255984785533663\n",
      "10.036494654164413\n",
      "9.831907780826228\n",
      "9.636214926694773\n",
      "9.4466199216203\n",
      "9.261800595143391\n",
      "9.081111426450226\n",
      "8.904217941271295\n",
      "8.730929059434562\n",
      "8.561120204393223\n",
      "8.394698029715538\n",
      "8.231584229047973\n",
      "8.071708097294424\n",
      "7.915003105185045\n",
      "7.761405314633699\n",
      "7.610852638567284\n",
      "7.463284488314539\n",
      "7.318641599004286\n",
      "7.176865936862871\n",
      "7.037900644325847\n",
      "6.901690002739273\n",
      "6.768179403369372\n",
      "6.637315322458849\n",
      "6.509045298370172\n",
      "6.383317909912513\n",
      "6.260082755433456\n",
      "6.1392904324788375\n",
      "6.020892517926362\n",
      "5.904841548545342\n",
      "5.791091001956645\n",
      "5.679595277976872\n",
      "5.570309680335469\n",
      "5.463190398755673\n",
      "5.35819449139133\n",
      "5.255279867612146\n",
      "5.15440527113034\n",
      "5.055530263461809\n",
      "4.958615207715168\n",
      "4.863621252702158\n",
      "4.770510317363027\n",
      "4.67924507550063\n",
      "4.589788940817153\n",
      "4.502106052247435\n",
      "4.4161612595830455\n",
      "4.331920109381294\n",
      "4.249348831153585\n",
      "4.168414323827546\n",
      "4.089084142477509\n",
      "4.01132648531802\n",
      "3.935110180955199\n",
      "3.8604046758907704\n",
      "3.787180022273824\n",
      "3.7154068658953534\n",
      "3.6450564344207796\n",
      "3.5761005258557335\n",
      "3.508511497240472\n",
      "3.4422622535684004\n",
      "3.3773262369242683\n",
      "3.3136774158376525\n",
      "3.2512902748475114\n",
      "3.190139804273556\n",
      "3.1302014901904176\n",
      "3.0714513046005303\n",
      "3.0138656958018126\n",
      "2.9574215789462914\n",
      "2.9020963267858892\n",
      "2.847867760601618\n",
      "2.79471414131262\n",
      "2.7426141607614234\n",
      "2.6915469331719617\n",
      "2.6414919867768987\n",
      "2.5924292556109387\n",
      "2.5443390714668057\n",
      "2.497202156010677\n",
      "2.4509996130539076\n",
      "2.405712920977954\n",
      "2.36132392530944\n",
      "2.3178148314424236\n",
      "2.275168197504913\n",
      "2.233366927366793\n",
      "2.1923942637863445\n",
      "2.15223378169263\n",
      "2.112869381601019\n",
      "2.0742852831592646\n",
      "2.0364660188214754\n",
      "1.9993964276475158\n",
      "1.9630616492253121\n",
      "1.9274471177136125\n",
      "1.892538556002869\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "for i in range(100):\n",
    "    outputs = np.dot(inputs, weights) + biases\n",
    "    deltas = outputs - targets\n",
    "    loss = np.sum(deltas ** 2) / 2 / observations\n",
    "    print(loss)\n",
    "    \n",
    "    deltas_scaled = deltas / observations\n",
    "    \n",
    "    weights = weights - learning_rate * np.dot(inputs.T, deltas_scaled)\n",
    "    biases = biases - learning_rate * np.sum(deltas_scaled)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.97426043]\n",
      " [-3.00211529]] [3.184936]\n"
     ]
    }
   ],
   "source": [
    "#Print weights and biases and see if we have worked correctly\n",
    "print(weights,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
